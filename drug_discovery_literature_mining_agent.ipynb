{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific Literature Mining Agents for Drug Discovery Research using smolagents\n",
    "\n",
    "This notebook demonstrates how to use the functions from the `drug_discovery_literature_mining.ipynb` notebook as tools for a smolagents agent. The agent will be used to research a specific topic across multiple literature sources (PubMed, Google Scholar, bioRxiv, Google Patents) and compile and summarize the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the Environment\n",
    "\n",
    "First, we need to install the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymed apify-client requests beautifulsoup4 transformers docling smolagents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for literature mining\n",
    "from pymed import PubMed\n",
    "from apify_client import ApifyClient\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "\n",
    "# Import smolagents libraries\n",
    "from smolagents import CodeAgent, tool, LiteLLMModel, HfApiModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining Literature Mining Tools\n",
    "\n",
    "We'll define the functions from the original notebook as tools for our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def pubmed_agent(query: str, max_results: int = 10) -> list:\n",
    "    \"\"\"\n",
    "    Search PubMed for scientific articles related to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for PubMed.\n",
    "        max_results: Maximum number of results to return (default: 10).\n",
    "        \n",
    "    Returns:\n",
    "        A list of dictionaries containing article information.\n",
    "    \"\"\"\n",
    "    pubmed = PubMed(tool=\"MyTool\", email=\"my@email.address\")\n",
    "    results = pubmed.query(query, max_results=max_results)\n",
    "    articles = [article.toDict() for article in results]\n",
    "    \n",
    "    # Extract relevant information for easier processing\n",
    "    simplified_articles = []\n",
    "    for article in articles:\n",
    "        simplified_article = {\n",
    "            'title': article.get('title', 'No title'),\n",
    "            'abstract': article.get('abstract', 'No abstract'),\n",
    "            'authors': ', '.join([author.get('lastname', '') + ' ' + author.get('firstname', '') \n",
    "                                for author in article.get('authors', [])]),\n",
    "            'journal': article.get('journal', 'No journal'),\n",
    "            'publication_date': article.get('publication_date', 'No date'),\n",
    "            'doi': article.get('doi', 'No DOI')\n",
    "        }\n",
    "        simplified_articles.append(simplified_article)\n",
    "    \n",
    "    return simplified_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def google_scholar_agent(keyword: str, max_results: int = 10) -> list:\n",
    "    \"\"\"\n",
    "    Search Google Scholar for scientific articles related to the keyword.\n",
    "    \n",
    "    Args:\n",
    "        keyword: The search keyword for Google Scholar.\n",
    "        max_results: Maximum number of results to return (default: 10).\n",
    "        \n",
    "    Returns:\n",
    "        A list of dictionaries containing article information.\n",
    "    \"\"\"\n",
    "    # Note: You need to replace <YOUR_API_TOKEN> with a valid Apify API token\n",
    "    # For demonstration purposes, we'll return a mock response\n",
    "    \n",
    "    # Uncomment the following code when you have a valid API token\n",
    "    # client = ApifyClient(\"<YOUR_API_TOKEN>\")\n",
    "    # run_input = {\n",
    "    #     \"keyword\": keyword,\n",
    "    #     \"proxyOptions\": {\"useApifyProxy\": True},\n",
    "    #     \"maxResults\": max_results\n",
    "    # }\n",
    "    # run = client.actor(\"marco.gullo/google-scholar-scraper\").call(run_input=run_input)\n",
    "    # return list(client.dataset(run[\"defaultDatasetId\"]).iterate_items())\n",
    "    \n",
    "    # Mock response for demonstration\n",
    "    return [\n",
    "        {\n",
    "            \"title\": f\"Mock Google Scholar Result 1 for {keyword}\",\n",
    "            \"authors\": \"Author A, Author B\",\n",
    "            \"publication\": \"Journal of Mock Science\",\n",
    "            \"year\": \"2023\",\n",
    "            \"cited_by\": 42,\n",
    "            \"link\": \"https://scholar.google.com/example1\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": f\"Mock Google Scholar Result 2 for {keyword}\",\n",
    "            \"authors\": \"Author C, Author D\",\n",
    "            \"publication\": \"International Journal of Mock Research\",\n",
    "            \"year\": \"2022\",\n",
    "            \"cited_by\": 28,\n",
    "            \"link\": \"https://scholar.google.com/example2\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def biorxiv_agent(query: str, max_results: int = 10) -> list:\n",
    "    \"\"\"\n",
    "    Search bioRxiv for preprints related to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for bioRxiv.\n",
    "        max_results: Maximum number of results to return (default: 10).\n",
    "        \n",
    "    Returns:\n",
    "        A list of dictionaries containing preprint information.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.biorxiv.org/details/biorxiv/{query}/0/{max_results}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()['collection']\n",
    "    else:\n",
    "        return [{\"error\": f\"Failed to fetch data from bioRxiv: {response.status_code}\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def google_patents_agent(query: str, max_results: int = 10) -> list:\n",
    "    \"\"\"\n",
    "    Search Google Patents for patents related to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for Google Patents.\n",
    "        max_results: Maximum number of results to return (default: 10).\n",
    "        \n",
    "    Returns:\n",
    "        A list of dictionaries containing patent information.\n",
    "    \"\"\"\n",
    "    # Note: Web scraping Google Patents might be against their terms of service\n",
    "    # For demonstration purposes, we'll return a mock response\n",
    "    \n",
    "    # Uncomment the following code at your own risk\n",
    "    # url = f\"https://patents.google.com/?q={query}&num={max_results}\"\n",
    "    # response = requests.get(url)\n",
    "    # soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # patents = soup.find_all('article', class_='result-item')\n",
    "    # return [{'title': p.find('h3').text, 'link': p.find('a')['href']} for p in patents]\n",
    "    \n",
    "    # Mock response for demonstration\n",
    "    return [\n",
    "        {\n",
    "            \"title\": f\"Mock Patent 1 for {query}\",\n",
    "            \"link\": \"https://patents.google.com/example1\",\n",
    "            \"inventors\": \"Inventor A, Inventor B\",\n",
    "            \"filing_date\": \"2022-01-15\",\n",
    "            \"publication_date\": \"2023-07-22\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": f\"Mock Patent 2 for {query}\",\n",
    "            \"link\": \"https://patents.google.com/example2\",\n",
    "            \"inventors\": \"Inventor C, Inventor D\",\n",
    "            \"filing_date\": \"2021-11-30\",\n",
    "            \"publication_date\": \"2023-05-18\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def analyze_document(document_text: str, questions: list) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze a document using a question-answering model.\n",
    "    \n",
    "    Args:\n",
    "        document_text: The text of the document to analyze.\n",
    "        questions: A list of questions to ask about the document.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary mapping questions to answers.\n",
    "    \"\"\"\n",
    "    # Split the document into sections\n",
    "    sections = document_text.split(\"## \")\n",
    "    sections = [s.strip() for s in sections if s.strip()]\n",
    "    \n",
    "    # Create a question-answering agent\n",
    "    question_answerer = pipeline(\"question-answering\")\n",
    "    \n",
    "    # Define the QA agent function\n",
    "    def qa_agent(document_sections, question_answerer):\n",
    "        def agent(question):\n",
    "            context = \"\\n\".join(document_sections)\n",
    "            result = question_answerer(question=question, context=context)\n",
    "            return result['answer']\n",
    "        return agent\n",
    "    \n",
    "    # Create the agent\n",
    "    agent = qa_agent(sections, question_answerer)\n",
    "    \n",
    "    # Get answers to the questions\n",
    "    answers = {}\n",
    "    for question in questions:\n",
    "        answer = agent(question)\n",
    "        answers[question] = answer\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a Research Agent\n",
    "\n",
    "Now we'll create a CodeAgent that uses the literature mining tools to research a specific topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which LLM engine to use\n",
    "# Uncomment one of the following options\n",
    "\n",
    "# Option 1: Use HfApiModel (default)\n",
    "model = HfApiModel()\n",
    "\n",
    "# Option 2: Use LiteLLMModel with GPT-4o\n",
    "# model = LiteLLMModel(model_id=\"gpt-4o\")\n",
    "\n",
    "# Option 3: Use LiteLLMModel with Claude\n",
    "# model = LiteLLMModel(model_id=\"anthropic/claude-3-5-sonnet-20240620\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the research agent\n",
    "research_agent = CodeAgent(\n",
    "    tools=[\n",
    "        pubmed_agent,\n",
    "        google_scholar_agent,\n",
    "        biorxiv_agent,\n",
    "        google_patents_agent,\n",
    "        analyze_document\n",
    "    ],\n",
    "    model=model,\n",
    "    max_steps=15,  # Limit the number of steps to avoid excessive API calls\n",
    "    verbosity_level=2  # Show detailed output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using the Research Agent\n",
    "\n",
    "Now we can use the research agent to research a specific topic across the literature sources and compile the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Research on novel drug delivery systems\n",
    "research_topic = \"\"\"\n",
    "Research the latest developments in nanoparticle-based drug delivery systems for cancer treatment. \n",
    "Focus on:\n",
    "1. Recent breakthroughs in the last 2 years\n",
    "2. Different types of nanoparticles being used\n",
    "3. Clinical trial status of these technologies\n",
    "4. Major challenges and limitations\n",
    "\n",
    "Compile a comprehensive summary of your findings with references.\n",
    "\"\"\"\n",
    "\n",
    "# Run the agent\n",
    "result = research_agent.run(research_topic)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. More Research Examples\n",
    "\n",
    "Here are some additional examples of research topics that can be explored using the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Research on CRISPR gene editing for rare diseases\n",
    "research_topic_2 = \"\"\"\n",
    "Research the application of CRISPR gene editing technologies for treating rare genetic diseases. \n",
    "Focus on:\n",
    "1. Recent clinical trials and their outcomes\n",
    "2. Specific rare diseases being targeted\n",
    "3. Delivery methods for CRISPR components\n",
    "4. Ethical considerations and regulatory status\n",
    "\n",
    "Compile a comprehensive summary of your findings with references.\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment to run this example\n",
    "# result_2 = research_agent.run(research_topic_2)\n",
    "# print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Research on AI-driven drug discovery\n",
    "research_topic_3 = \"\"\"\n",
    "Research the role of artificial intelligence in accelerating drug discovery and development. \n",
    "Focus on:\n",
    "1. AI algorithms and models being used\n",
    "2. Success stories and case studies\n",
    "3. Companies and research institutions leading the field\n",
    "4. Future prospects and challenges\n",
    "\n",
    "Compile a comprehensive summary of your findings with references.\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment to run this example\n",
    "# result_3 = research_agent.run(research_topic_3)\n",
    "# print(result_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Research Function\n",
    "\n",
    "Let's create a function that makes it easy to conduct research on any topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_research(topic, focus_areas=None, max_results_per_source=5):\n",
    "    \"\"\"\n",
    "    Conduct research on a specific topic across multiple literature sources.\n",
    "    \n",
    "    Args:\n",
    "        topic: The main research topic.\n",
    "        focus_areas: A list of specific areas to focus on (optional).\n",
    "        max_results_per_source: Maximum number of results to retrieve from each source.\n",
    "        \n",
    "    Returns:\n",
    "        A comprehensive research summary.\n",
    "    \"\"\"\n",
    "    # Construct the research prompt\n",
    "    prompt = f\"Research the topic of {topic}.\\n\"\n",
    "    \n",
    "    if focus_areas:\n",
    "        prompt += \"Focus on:\\n\"\n",
    "        for i, area in enumerate(focus_areas, 1):\n",
    "            prompt += f\"{i}. {area}\\n\"\n",
    "    \n",
    "    prompt += f\"\\nUse a maximum of {max_results_per_source} results from each source.\\n\"\n",
    "    prompt += \"\\nCompile a comprehensive summary of your findings with references.\"\n",
    "    \n",
    "    # Run the agent\n",
    "    result = research_agent.run(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the conduct_research function\n",
    "research_result = conduct_research(\n",
    "    topic=\"microbiome-based therapeutics for inflammatory bowel disease\",\n",
    "    focus_areas=[\n",
    "        \"Current clinical trials\",\n",
    "        \"Mechanisms of action\",\n",
    "        \"Comparison with traditional treatments\",\n",
    "        \"Safety and efficacy data\"\n",
    "    ],\n",
    "    max_results_per_source=3\n",
    ")\n",
    "\n",
    "# Uncomment to run this example\n",
    "# print(research_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use smolagents to create a research agent that can search for scientific literature across multiple sources, analyze the findings, and compile a comprehensive summary. This approach can be extended to other research domains and customized for specific research needs.\n",
    "\n",
    "Key benefits of using smolagents for literature mining:\n",
    "1. Automated search across multiple sources\n",
    "2. Consistent analysis and summarization\n",
    "3. Ability to focus on specific aspects of a research topic\n",
    "4. Integration with various LLM engines\n",
    "5. Extensibility with additional tools and sources\n",
    "\n",
    "Next steps could include:\n",
    "- Adding more literature sources (e.g., Scopus, Web of Science)\n",
    "- Implementing more sophisticated document analysis tools\n",
    "- Creating specialized agents for different research domains\n",
    "- Integrating with citation management systems\n",
    "- Adding visualization tools for research findings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}